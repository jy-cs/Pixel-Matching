{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Part-I Camera Calibration using OpenCV"],"metadata":{"id":"8lOQG4TYq0NW"}},{"cell_type":"markdown","source":[">## Introduction\n","This program calibrates an RGB camera using the builtin OpenCV function.\n","The input files are a file, containing a list of 3D coordinates, and a file, containing the corresponding 2D pixel coordinates.\n","The output is a 3x4 calibration matrix and the average errors (difference between projected points and original pixels).\n"],"metadata":{"id":"dI1MoqEsrl7J"}},{"cell_type":"code","source":["import numpy as np\n","import cv2 as cv"],"metadata":{"id":"kM5RWYrhZane"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[">## 1 Read Input Files and Construct Matrices $\\textbf{P}$ and $\\textbf{Q}$\n","In this section, we read $n$ pairs of points, $(P_i, p_i)$, from input files containing 2D and 3D coordinates. \\\\\n","We construct two metrices called $\\textbf{P}$ which represents the 3D coordinates of object in scene coordinate system and $\\textbf{Q}$ which represents the 2D coordinates corresponding pixel in image coordinate system. \\\\\n","The shape of $\\textbf{P}$ is originally $\\textbf{(n, 3)}$ and shape of $\\textbf{Q}$ is $\\textbf{(n, 2)}$ where $\\textbf{n}$ is the number of given points.  \n","<!-- Then, we construct the matrix $\\textbf{A}\\in \\textbf{M}_{(2n)\\times 12}(\\mathbb{R})$ as follows,\n","\\begin{align}\n","        \\textbf{A}\n","        &= \\begin{pmatrix}\n","        \\textbf{G_1} \\\\\n","        \\textbf{G_2} \\\\\n","        ... \\\\\n","        \\textbf{G_n}\n","    \\end{pmatrix}, \\text{where } \\textbf{G}_j\n","        =\\begin{pmatrix}\n","        -X_j & -Y_j & -Z_j & -1 & \\vec{0}^\\top & u_jX_j & u_jY_j & u_jZ_j & u_j \\\\\n","        \\vec{0}^\\top & -X_j & -Y_j & -Z_j & -1 & v_jX_j & v_jY_j & v_jZ_j & v_j\n","    \\end{pmatrix} \\\\\n","        &=\\begin{pmatrix}\n","        -X_1 & -Y_1 & -Z_1 & -1 & 0 & 0 & 0 & 0 & u_1X_1 & u_1Y_1 & u_1Z_1 & u_1 \\\\\n","        0 & 0 & 0 & 0 & -X_1 & -Y_1 & -Z_1 & -1 & v_1X_1 & v_1Y_1 & v_1Z_1 & v_1 \\\\\n","        -X_2 & -Y_2 & -Z_2 & -1 & 0 & 0 & 0 & 0 & u_2X_2 & u_2Y_2 & u_2Z_2 & u_2 \\\\\n","        0 & 0 & 0 & 0 & -X_2 & -Y_2 & -Z_2 & -1 & v_2X_2 & v_2Y_2 & v_2Z_2 & v_2 \\\\\n","        &&&&&... \\\\\n","        -X_n & -Y_n & -Z_n & -1 & 0 & 0 & 0 & 0 & u_nX_n & u_nY_n & u_nZ_n & u_n \\\\\n","        0 & 0 & 0 & 0 & -X_n & -Y_n & -Z_n & -1 & v_nX_n & v_nY_n & v_nZ_n & v_n\n","        \\end{pmatrix}\n","    \\end{align}\n","In addition, we initialize the matrix $P$ from the input 3D coordinate file, defined as the following,\n","\\begin{align} P = \\begin{pmatrix}\n","        X_1 & ... & X_i & ... & X_n \\\\\n","        Y_1 & ... & Y_i & ... & Y_n \\\\\n","        Z_1 & ... & Z_i & ... & Z_n \\\\\n","        1   & ... & 1   & ... & 1\n","    \\end{pmatrix} \\in M_{4\\times n}(\\mathbb{R})\n","    \\end{align}\n","Also, we initialize the matrix $Q$ from the input 2D coordinate file, defined as the following,\n","\\begin{align} Q = \\begin{pmatrix}\n","        u_1 & ... & u_i & ... & u_n \\\\\n","        v_1 & ... & v_i & ... & v_n \\\\\n","        1   & ... & 1   & ... & 1\n","    \\end{pmatrix} \\in M_{3\\times n}(\\mathbb{R})\n","    \\end{align}\n","Based on the perspective projection equation, $P$ and $Q$ are expected to have the following property,\n","\\begin{align} \\exists \\lambda_1, ..., \\lambda_n,\n","        Q = MP(\\lambda_1, ..., \\lambda_n)^\\top\n","    \\end{align} -->"],"metadata":{"id":"YjUOmyYQtOPr"}},{"cell_type":"code","source":["# define paths of the two input files\n","path_2d = \"2D.txt\"\n","path_3d = \"3D.txt\"\n","\n","# opening both the files in reading modes\n","with open(path_2d) as f_2d, open(path_3d) as f_3d:\n","    num_line_2d = int(f_2d.readline().split('\\n')[0])\n","    num_line_3d = int(f_3d.readline().split('\\n')[0])\n","    if num_line_2d != num_line_3d:\n","        print(\"Error: Number of Points does NOT Match in 2D.text and 3D.txt\")\n","        exit()\n","    # initialize matrics P and Q for input files\n","    P = np.ones((num_line_3d, 3))\n","    Q = np.ones((num_line_3d, 2))\n","\n","    # initialize Matrix A\n","    A = np.zeros((num_line_3d * 2, 12))\n","\n","    # fill Matrix P, Q, and A\n","    while num_line_2d > 0:\n","        # define the index of point, i\n","        i = num_line_3d - num_line_2d\n","\n","        # define 2d coord (u,v)\n","        line_2d = f_2d.readline().split(' ')\n","        u = float(line_2d[0])\n","        v = float(line_2d[1])\n","\n","        # fill matrix Q with u, v\n","        Q[i, 0] = u\n","        Q[i, 1] = v\n","\n","        # define 3d coord (x,y,z)\n","        line_3d_raw = f_3d.readline().split(' ')\n","        line_3d_fl = []\n","        for j in range(len(line_3d_raw)):\n","            if len(line_3d_raw[j]) > 0:\n","                line_3d_fl.append(float(line_3d_raw[j]))\n","        x = line_3d_fl[0]\n","        y = line_3d_fl[1]\n","        z = line_3d_fl[2]\n","\n","        # fill matrix P with x, y, z\n","        P[i, 0] = x\n","        P[i, 1] = y\n","        # P[i, 2] = z\n","        # Z = 0, explained later\n","        P[i, 2] = 0\n","\n","        # update\n","        num_line_2d -= 1\n","\n","#print(P)\n","#print(Q)"],"metadata":{"id":"CJoNdYOVsXtR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[">## 2 Structuring the Input\n","\n","We are going to use the $\\textbf{calibrateCamera}$ function of OpenCV. The required parameters for it are as following. \\\\\n","\n","<ul>\n","  <li> ObjectPoints </li>\n","  <ul>\n","    <li> Datatype: InputArrayOfArray of $\\textit{float32}$ </li>\n","    <li> Expected Shape : $\\textit{(n_images, n_points, 3)}$ where n_images are the number of images and n_points are number of points per image </li>\n","  </ul>\n","  <li> ImagePoints </li>\n","  <ul>\n","    <li> Datatype: InputArrayOfArray of $\\textit{float32}$</li>\n","    <li> Expected Shape : $\\textit{(n_images, n_points, 1, 2)}$ where n_images are the number of images and n_points are number of points per image </li>\n","  </ul>\n","</ul>\n","\n","It is assumed that in single image, the object with checkbox pattern is kept parallel to the Z-axis of Object coordinate system and it is proven that it doesn't affect the generalization of the calculation. Moreover, the function expects planar coordinates for one image. So we have kept Z=0 for all the points and to differentiate the levels, we have considered them to be in different images so in our case, we have 3 unique values for Z and 9 points for each values. That's why we will reshape our P accordingly. \\\\\n","And as for the image size, we were only given the points so we have assumed it to be (100,100)."],"metadata":{"id":"hmU8oVR14aka"}},{"cell_type":"code","source":["# Final Object and Image points array\n","objectPoints = []\n","imagePoints = []\n","\n","# Dividing coordinates according to planes\n","for i in range(3):\n","  P_slice = P[9*i:9*(i+1)].reshape(9, 3).astype('float32')\n","  Q_slice = Q[9*i:9*(i+1)].reshape(9, 1, 2).astype('float32')\n","  objectPoints.append(P_slice)\n","  imagePoints.append(Q_slice)\n","\n","# Converting lists to np-array\n","objectPoints = np.array(objectPoints)\n","imagePoints = np.array(imagePoints)\n","\n","# print(objectPoints.shape)\n","# print(imagePoints.shape)"],"metadata":{"id":"Qmvdpg4QmoNd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[">## 3 Function Call $\\textbf{calibrateCamera}$\n","\n","The function $\\textbf{calibrateCamera}$ returns 5 values.\n","\n","<ul>\n","  <li> ret </li>\n","  <ld> - Status of execution </ld>\n","  <li> mtx </li>\n","  <ld> - Camera metrix of its intrinsic parameters </ld>\n","  <li> dist </li>\n","  <ld> - Distortion coefficients</ld>\n","  <li> rvecs </li>\n","  <ld> - Array of rotation vector </ld>\n","  <li> tvecs </li>\n","  <ld> - Array of translation vector </ld>\n","</ul>\n","\n","For more details, click [here](https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html)"],"metadata":{"id":"DWGG4gUEMiqF"}},{"cell_type":"code","source":["# Assuming image size to be (100, 100)\n","img_size = (100, 100)\n","ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objectPoints, imagePoints, img_size, None, None)\n","\n","# print(mtx.shape)"],"metadata":{"id":"cX146IFjQ4aJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[">## 4 Calculating the Perspective Projection Matrix\n","\n","As we have considered that points with different values of Z falls on different image, the function returns 3 pair of rotation and translation vectors. Using them, we can calculate 3 perspective projection matrix for 3 images.  "],"metadata":{"id":"Jmv5ayvYTsW2"}},{"cell_type":"code","source":["# List of projection matrices\n","p_mtx = []\n","\n","for i in range(len(objectPoints)):\n","  # Function to convert rotation vector to rotation matrix\n","  R = cv.Rodrigues(rvecs[i])[0]\n","  t = tvecs[i]\n","  Rt = np.concatenate([R,t], axis=-1) # [R|t]\n","  p_mtx.append(np.matmul(mtx,Rt)) # A[R|t]"],"metadata":{"id":"zwy7xucHaV3s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[">## 5 Coordinate Prediction and Error Measurement\n","\n","As we already know that, \\\\\n","$p = MP$ \\\\\n","where $\\textbf{p}$ is 2D image coordinates, $\\textbf{P}$ is 3D object coordinates and $\\textbf{M}$ is 3x4 projective matrix.\n","\n","So, we will multiply each points with M to get its 2D projection. And we will take its euclidean distance from the given value to calculate its mean error."],"metadata":{"id":"K0UL_2toUvZt"}},{"cell_type":"code","source":["# Initialize mean error as 0\n","mean_error = 0\n","\n","# Calculating Total number of points\n","total_points = objectPoints.shape[0] * objectPoints.shape[1]\n","\n","# Loop through all coordinates to get the prediction and calculate its euclidean distance from original coordinates\n","for i in range(objectPoints.shape[0]):\n","  for j in range(objectPoints.shape[1]):\n","    current_point = np.concatenate([objectPoints[i, j, :], [1]], axis=0) # Fetching points one by one\n","    predicted_point = np.matmul(p_mtx[i], current_point) # Prediction by multiplication\n","    predicted_point = predicted_point / predicted_point[-1] # Adjusting the scale factor\n","    predicted_point = predicted_point[:2].astype('float32') # Type casting\n","\n","    error = cv.norm(imagePoints[i, j, 0, :], predicted_point, cv.NORM_L2)/total_points\n","    mean_error = mean_error + error\n","\n","# mean_error = mean_error / P.shape[0]\n","print(\"Mean Error : \", mean_error)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKgFlt9_1534","outputId":"61098213-9e0c-462f-d84c-97b666c22de1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Error :  9.316497449091349e-06\n"]}]},{"cell_type":"markdown","source":[">## Extra:\n","\n","We can directly predict the 2D coordinates using $\\textbf{projectPoints}$ function of OpenCV. This doesn't require us to explicitely calculate projection matrix and we can also calculate error using this. It is observed that it actually gives even better result."],"metadata":{"id":"3tlLglJ9Wv9z"}},{"cell_type":"code","source":["mean_error = 0\n","for i in range(len(objectPoints)):\n","    imgpoints2, _ = cv.projectPoints(objectPoints[i], rvecs[i], tvecs[i], mtx, dist)\n","    error = cv.norm(imagePoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n","    mean_error += error\n","print( \"total error: {}\".format(mean_error/len(objectPoints)) )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOYgaSCqKAov","outputId":"e6d7e8fa-6a8e-4af4-f992-342e6fb5e78e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total error: 0.0\n"]}]},{"cell_type":"markdown","source":[">## 6 Conclusion\n","The calibration matrix we calculated in section 2 is valid because the average error is significantly small."],"metadata":{"id":"5Tk75PWXoeoT"}}]}